ðŸ§  NLP with spaCy A Natural Language Processing (NLP) project using spaCy for text analysis, including tokenization, part-of-speech tagging, named entity recognition (NER), 
and dependency parsing. It enables efficient text preprocessing, linguistic analysis, and custom NLP model training for various applications. ðŸš€


# NLP-using-Spacy

**Active Learning-Based Named Entity Recognition (NER) Using spaCy**
This project focuses on developing a custom Named Entity Recognition (NER) model using spaCy with Active Learning to enhance annotation efficiency. The model is trained on the WNUT-16 dataset, which includes noisy and informal social media text.

**Key Features**
Active Learning Strategy: Utilizes confidence-based sampling for efficient manual annotation.
Custom NER Pipeline: Implements a trainable spaCy pipeline with rule-based matching and tokenization.
Iterative Model Training: Involves multiple iterations of annotation, training, and evaluation to improve performance.
Performance Evaluation: Uses precision, recall, and F1-score to assess model effectiveness.
Scalability & Deployment: Ensures model generalizability for real-world applications.

**Results**
Achieved 85% F1-score on the training set but faced challenges with generalization on dev and test datasets.
Identified areas for improvement, including parameter tuning, more precise annotations, and additional training iterations.

**Future Improvements**
Enhancing model accuracy by refining sampling strategies.
Expanding annotation coverage to improve recognition of low-frequency entities.
Optimizing hyperparameters for better generalization.
This project demonstrates the potential of Active Learning to make NER annotation more efficient while leveraging spaCy for scalable NLP solutions.
